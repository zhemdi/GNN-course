{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: GNNs for Molecular Applications in Geometric Deep Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume:\n",
    "The second part of the course focuses on the application of GNNs to molecular data. We will explore different geometric deep learning approaches specifically designed for handling molecules, from small organic compounds to large biomolecules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "### 1. Introduction to Molecular Geometric Data\n",
    "- **Definition of Molecular Geometric Data:** Understand how molecular structures are represented as geometric data.\n",
    "- **Challenges in Molecular Data Processing:** Discuss challenges like irregularity, invariance to rotation/translation, and varying molecular size.\n",
    "\n",
    "### 2. Invariant Networks\n",
    "- **Concept of Invariance:** Learn the importance of invariant properties for molecular data.\n",
    "- **Key Architectures:** Overview of models like SchNet and Invariant Point Attention.\n",
    "- **Applications:** Use cases in molecular property prediction and drug discovery.\n",
    "\n",
    "### 3. Cartesian Networks\n",
    "- **Cartesian Coordinates in Molecular GNNs:** How GNNs use Cartesian data to model atomic interactions.\n",
    "- **Key Architectures:** Examples like GVP-GNN and E(n)-GNN.\n",
    "- **Applications:** Predicting molecular properties and dynamics.\n",
    "\n",
    "### 4. Spherical Networks\n",
    "- **Introduction to Spherical Molecular Data:** Understand how data on spherical domains is used in molecular modeling.\n",
    "- **Spherical GNNs:** Introduction to architectures like Tensor Fields Networks.\n",
    "- **Applications:** Modeling molecular conformations and protein structures.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### References\n",
    "- Based on: [\"Survey of Geometric GNNs for 3D Atomic Systems\"](https://arxiv.org/pdf/2312.07511)\n",
    "\n",
    "![Geometric GNNs for 3D atomic system](https://miro.medium.com/v2/resize:fit:1400/1*AYsGjZhbdr701OndCvnfng.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Molecular Geometric Data\n",
    "\n",
    "### Definition of Molecular Geometric Data\n",
    "Molecular structures are typically represented as point clouds where each point corresponds to an atom in 3D space. The geometric properties, such as atomic positions and bond lengths, are crucial for understanding molecular behavior and properties.\n",
    "\n",
    "### Challenges in Molecular Data Processing\n",
    "Processing molecular data involves several challenges:\n",
    "- **Irregularity:** Molecules can vary greatly in size and shape.\n",
    "- **Invariance to Rotation/Translation:** Molecular properties should not change under rotation or translation.\n",
    "- **Varying Molecular Size:** Models must handle small organic molecules and large proteins alike.\n",
    "\n",
    "### Applications in Molecular Data\n",
    "Molecular data is used in several key applications:\n",
    "- **Molecular Property Prediction:** Estimating properties like binding affinity, reactivity, or toxicity.\n",
    "- **Drug Discovery:** Identifying potential drug candidates by modeling molecule interactions.\n",
    "- **Protein Structure Prediction:** Determining 3D protein structures from amino acid sequences.\n",
    "\n",
    "### Molecules as Graphs\n",
    "Molecules can be represented as graphs where atoms are nodes and bonds are edges. This graph representation allows GNNs to learn complex molecular relationships and predict their properties accurately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Invariant Networks\n",
    "\n",
    "### Concept of Invariance\n",
    "Invariant networks in geometric deep learning ensure that molecular representations remain unchanged under transformations like rotations and translations. This invariance is crucial for molecular data, where the orientation or position of the molecule should not affect the prediction.\n",
    "\n",
    "### Key Architectures: SchNet and Invariant Point Attention\n",
    "\n",
    "#### SchNet\n",
    "**SchNet** is a neural network designed for predicting molecular properties using 3D geometries of molecules. It employs continuous-filter convolutional layers that operate on atomistic point clouds, making it invariant to rotations and translations.\n",
    "\n",
    "![SchNet Architecture](https://d3i71xaburhd42.cloudfront.net/5bf31dc4bd54b623008c13f8bc8954dc7c9a2d80/4-Figure2-1.png)\n",
    "\n",
    "**Paper Link:** [SchNet: A Continuous-filter Convolutional Neural Network for Modeling Quantum Interactions](https://arxiv.org/abs/1706.08566)\n",
    "\n",
    "#### Invariant Point Attention\n",
    "**Invariant Point Attention (IPA)** is a technique used in models like AlphaFold for processing geometric data, particularly for molecular modeling. IPA ensures the attention mechanism is invariant to 3D transformations, making it effective for tasks like predicting protein folding.\n",
    "\n",
    "![Invariant Point Attention](https://github.com/lucidrains/invariant-point-attention/blob/main/ipa.png?raw=true)\n",
    "\n",
    "**Paper Link:** [AlphaFold: Deep Learning-Based Protein Structure Prediction](https://www.nature.com/articles/s41586-021-03819-2)\n",
    "\n",
    "### Applications\n",
    "- **Molecular Property Prediction:** Estimating molecular properties such as binding affinity and reactivity.\n",
    "- **Drug Discovery:** Identifying new drug candidates by modeling molecular interactions.\n",
    "\n",
    "### Implementing an Invariant Network with `MessagePassing`\n",
    "\n",
    "Below is a simple example of an invariant network using the `MessagePassing` class from PyTorch Geometric:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class InvariantMPNN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, num_rbf=16):\n",
    "        super(InvariantMPNN, self).__init__(aggr='add')\n",
    "        self.lin = Linear(in_channels, out_channels)\n",
    "        self.dist_lin = Linear(num_rbf, out_channels)  # Linear transformation for RBF-transformed distances\n",
    "        self.rbf_centers = torch.linspace(0, 5, num_rbf)  # Radial basis function centers\n",
    "        self.rbf_gamma = torch.tensor(1.0)  # Gamma parameter for RBF\n",
    "\n",
    "    def forward(self, x, pos, edge_index):\n",
    "        # x: Node features\n",
    "        # pos: Node coordinates\n",
    "        # edge_index: Edge indices\n",
    "\n",
    "        # Calculate distances between connected nodes\n",
    "        row, col = edge_index\n",
    "        edge_vectors = pos[row] - pos[col]\n",
    "        distances = torch.norm(edge_vectors, p=2, dim=-1).unsqueeze(-1)\n",
    "        \n",
    "        # Compute RBF of distances\n",
    "        rbf = torch.exp(-self.rbf_gamma * (distances - self.rbf_centers) ** 2)\n",
    "\n",
    "        # Propagate messages\n",
    "        return self.propagate(edge_index, x=x, rbf=rbf)\n",
    "\n",
    "    def message(self, x_j, rbf):\n",
    "        # x_j: Source node features\n",
    "        # rbf: RBF-transformed distance features\n",
    "\n",
    "        edge_features = self.dist_lin(rbf)  # Transform RBF features\n",
    "        return self.lin(x_j) + edge_features  # Combine node and edge features\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out: Aggregated messages\n",
    "        return F.relu(aggr_out)  # Apply ReLU non-linearity\n",
    "\n",
    "# Example usage\n",
    "node_features = torch.randn(4, 3)  # 4 nodes, 3 features per node\n",
    "node_coords = torch.randn(4, 3)  # 4 nodes, 3D coordinates\n",
    "edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 0]], dtype=torch.long)  # Edges in COO format\n",
    "\n",
    "model = InvariantMPNN(in_channels=3, out_channels=2)\n",
    "output = model(node_features, node_coords, edge_index)\n",
    "\n",
    "print(\"Output Node Features:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of the Code:\n",
    "\n",
    "* **Distance Calculation:** Computes Euclidean distances between connected nodes.\n",
    "* **Radial Basis Function (RBF):** Transforms distances into edge features using RBF.\n",
    "* **Message Passing:** Uses transformed edge features along with node features for message passing.\n",
    "* **Update Function:** Applies ReLU activation to aggregated messages to update node features.\n",
    "\n",
    "This implementation makes the MPNN invariant to rotations and translations by using distance-based features, making it well-suited for molecular applications such as property prediction and drug discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equivariant Networks\n",
    "![Invariance vs Equivariance](Figure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cartesian Networks\n",
    "\n",
    "### Cartesian Coordinates in Molecular GNNs\n",
    "\n",
    "Cartesian networks use Cartesian coordinates to model atomic interactions in molecules. Each atom's position in 3D space is represented by its Cartesian coordinates $(x, y, z)$. These coordinates are used to compute distances and angles between atoms, which are fundamental for understanding molecular properties and dynamics.\n",
    "\n",
    "### Key Architectures: GVP-GNN and E(n)-GNN\n",
    "\n",
    "#### 1. **Geometric Vector Perceptron (GVP-GNN)**\n",
    "The **GVP-GNN** is designed for molecular systems, integrating geometric information by using both scalar and vector features. It leverages vector operations to maintain rotational and translational invariance, allowing it to predict molecular properties that depend on atomic positions.\n",
    "\n",
    "![GVP-GNN Architecture](https://raphael.tc.com/publication/gvp/featured_hu9b7018f8c7956abbafe4971f4d4d6c72_752084_720x0_resize_lanczos_2.png)\n",
    "\n",
    "- **Paper Link:** [Learning Protein Structure with a Differentiable Simulator](https://arxiv.org/abs/2009.01411)\n",
    "\n",
    "#### 2. **E(n)-Equivariant Graph Neural Networks (E(n)-GNN)**\n",
    "**E(n)-GNN** extends GNNs to be equivariant under Euclidean transformations (translations, rotations, and reflections). This network computes features invariant to molecular transformations by using equivariant convolutions that process geometric data in a way consistent with physical laws.\n",
    "\n",
    "- **Key Idea:** E(n)-GNN maintains equivariance by incorporating tensor operations that respect the symmetries of the Euclidean space in which the molecules exist.\n",
    "\n",
    "![E(n)-GNN Architecture](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41467-022-29939-5/MediaObjects/41467_2022_29939_Fig1_HTML.png)\n",
    "\n",
    "- **Paper Link:** [E(n) Equivariant Graph Neural Networks](https://arxiv.org/abs/2102.09844)\n",
    "\n",
    "### Applications\n",
    "\n",
    "- **Predicting Molecular Properties:** GVP-GNN and E(n)-GNN are used for tasks such as predicting binding affinities, chemical reactivity, and electronic properties.\n",
    "- **Modeling Molecular Dynamics:** These architectures help simulate molecular motions and interactions over time, providing insights into complex molecular behaviors like folding and binding. \n",
    "\n",
    "### Mathematical Formulation of E(n)-GNN\n",
    "\n",
    "The E(n)-GNN updates the node features $h_i$ and coordinates $x_i$ for each node $i$ as follows:\n",
    "\n",
    "1. **Node Update:**\n",
    "$$\n",
    "h_i' = h_i + \\sum_{j \\in \\mathcal{N}(i)} f_{\\text{node}}\\left(h_i, h_j, ||x_i - x_j||\\right)\n",
    "$$\n",
    "where:\n",
    "- $h_i$ is the feature of node $i$.\n",
    "- $x_i$ is the coordinate of node $i$.\n",
    "- $\\mathcal{N}(i)$ is the set of neighbors of node $i$.\n",
    "- $f_{\\text{node}}$ is a learnable function.\n",
    "\n",
    "2. **Coordinate Update:**\n",
    "$$\n",
    "x_i' = x_i + \\frac{1}{| \\mathcal{N}(i) |} \\sum_{j \\in \\mathcal{N}(i)} (x_j - x_i) \\cdot g_{\\text{coord}}(h_i, h_j, ||x_i - x_j||)\n",
    "$$\n",
    "where:\n",
    "- $g_{\\text{coord}}$ is a learnable function.\n",
    "\n",
    "### Code Snippet: Implementing a Simple Cartesian Network\n",
    "\n",
    "Here is a simple implementation of a Cartesian-based GNN layer using PyTorch Geometric:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "class CartesianGNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CartesianGNNLayer, self).__init__(aggr='add')  # Aggregation function: 'add'\n",
    "        self.linear = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, pos, edge_index):\n",
    "        # Compute distances between nodes\n",
    "        row, col = edge_index\n",
    "        diff = pos[row] - pos[col]\n",
    "        distances = diff.norm(dim=-1).unsqueeze(-1)\n",
    "\n",
    "        # Apply message passing\n",
    "        return self.propagate(edge_index, x=x, dist=distances)\n",
    "\n",
    "    def message(self, x_j, dist):\n",
    "        # Message function using distances\n",
    "        return self.linear(x_j) * dist\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Update function\n",
    "        return aggr_out\n",
    "\n",
    "# Example usage\n",
    "x = torch.randn(10, 3)  # 10 nodes, 3 features per node\n",
    "pos = torch.randn(10, 3)  # 10 nodes, 3D positions\n",
    "edge_index = torch.tensor([[0, 1, 2], [1, 2, 0]], dtype=torch.long)  # Edge index\n",
    "\n",
    "layer = CartesianGNNLayer(in_channels=3, out_channels=2)\n",
    "out = layer(x, pos, edge_index)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Spherical Networks\n",
    "\n",
    "#### Introduction to Spherical Molecular Data\n",
    "In molecular modeling, spherical data represents angular information, such as bond angles and orientations of atomic groups. This type of data is crucial for understanding molecular shapes, conformations, and interactions. Spherical networks leverage the properties of spherical harmonics to manage these angular symmetries.\n",
    "\n",
    "#### Spherical Harmonics and Irreducible Representations\n",
    "Spherical harmonics provide a mathematical basis for functions on a sphere, which are essential for describing the rotation-equivariant properties of features in geometric data.\n",
    "\n",
    "1. **0-Degree Irreps**: These are scalars and are invariant under rotation, providing a basic representation of features that do not change with orientation.\n",
    "\n",
    "2. **Higher-Degree Irreps**: Higher-degree irreps (e.g., 1, 2, 3, ...) represent more complex geometric features, such as vectors (degree 1) and tensors (degree 2), that transform predictably under rotations. These are essential for capturing directional and orientational information in molecules.\n",
    "\n",
    "\n",
    "![Spherical Harmonics](https://upload.wikimedia.org/wikipedia/commons/7/74/Real_Spherical_Harmonics_Figure_Table_Complex_Radial_Magnitude.gif)\n",
    "\n",
    "3. **Tensor Product $ \\otimes_{l_1, l_2}^{l_3} $**: This denotes the coupling of two irreducible representations of degrees $ l_1 $ and $ l_2 $ to produce an output of degree $ l_3 $. It combines features in a rotation-equivariant way, ensuring that the result respects the underlying symmetry.\n",
    "\n",
    "#### Spherical GNNs\n",
    "\n",
    "In spherical GNNs, message passing is defined by projecting features onto a spherical basis:\n",
    "\n",
    "$$\n",
    "\\mathbf{m}^{l_3}_{ij} = \\sum_{l_1, l_2} \\mathbf{f}^{l_1}_j \\otimes_{l_1, l_2}^{l_3} Y^{l_2} (\\vec{r}_{ji})\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\mathbf{f}^{l_1}_j $ are the features of degree $ l_1 $ of node $ j $.\n",
    "- $ Y^{l_2} (\\vec{r}_{ji}) $ are spherical harmonics representing the angular part of the position vector $ \\vec{r}_{ji} = \\vec{r}_{j} - \\vec{r}_{i} $.\n",
    "\n",
    "The updated features of degree $ l_3 $ for node $ i $ are computed by aggregating messages from its neighbors:\n",
    "\n",
    "$$\n",
    "\\mathbf{f}'^{l_3}_i = \\sum_{j \\in N(i)} \\mathbf{m}^{l_3}_{ij}\n",
    "$$\n",
    "\n",
    "#### Example: Tensor Field Networks (TFN)\n",
    "**Tensor Field Networks (TFNs)** are an example of spherical GNNs that maintain equivariance under rotations and translations. TFNs use spherical harmonics to represent molecular data and perform equivariant message passing, ensuring the model respects the geometric properties of the data.\n",
    "\n",
    "- **Feature Transformation**: Convert atomic coordinates to a spherical basis.\n",
    "- **Equivariant Convolution**: Use the irreps to convolve features, preserving rotational symmetry.\n",
    "- **Feature Aggregation**: Aggregate the transformed features from neighboring atoms to update the central atom's features.\n",
    "\n",
    "#### Applications\n",
    "- **Modeling Molecular Conformations**: Predicts molecular shapes and movements.\n",
    "- **Protein Structure Prediction**: Helps determine the 3D structures of proteins accurately.\n",
    "\n",
    "#### Illustration of Tensor Product\n",
    "\n",
    "![Tensor Product](https://ccr-cheng.github.io/assets/img/221207tfn/tensor_product.png)\n",
    "\n",
    "TFNs effectively leverage these principles to handle complex molecular data while preserving the essential geometric properties required for accurate molecular modeling.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of a Simple Spherical GNN Layer\n",
    "In this section, we will implement a basic spherical GNN layer. This layer computes radial basis functions (RBF) of distances between nodes and spherical harmonics of the angular part of the vectors between nodes. The input degree is 0, and the output degree is 2.\n",
    "\n",
    "We will use predefined functions to compute spherical harmonics and tensor products, and we will load Clebsch-Gordan coefficients to handle the operations correctly.\n",
    "\n",
    "Step-by-Step Implementation\n",
    "1. Define spherical harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associated_legendre_polynomials(L, x):\n",
    "    \"\"\"\n",
    "    Compute the associated Legendre polynomials.\n",
    "\n",
    "    Parameters:\n",
    "    L (int): The maximum degree of the polynomials.\n",
    "    x (torch.Tensor): The input tensor.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: A tensor containing the associated Legendre polynomials.\n",
    "    \"\"\"\n",
    "    P = [torch.ones_like(x) for _ in range((L+1)*L//2)]\n",
    "    \n",
    "    # Compute the polynomials for l in range(1, L)\n",
    "    for l in range(1, L):\n",
    "        P[(l+3)*l//2] = - np.sqrt((2*l-1)/(2*l)) * torch.sqrt(1-x**2) * P[(l+2)*(l-1)//2]\n",
    "    \n",
    "    # Compute the polynomials for m in range(L-1)\n",
    "    for m in range(L-1):\n",
    "        P[(m+2)*(m+1)//2+m] = x * np.sqrt(2*m+1) * P[(m+1)*m//2+m]\n",
    "        for l in range(m+2, L):\n",
    "            P[(l+1)*l//2+m] = ((2*l-1)*x*P[l*(l-1)//2 + m]/np.sqrt((l**2-m**2)) - P[(l-1)*(l-2)//2+m]*np.sqrt(((l-1)**2-m**2)/(l**2-m**2)))\n",
    "    return torch.stack(P, dim=0)\n",
    "\n",
    "def spherical_harmonics(L, THETA, PHI, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "    \"\"\"\n",
    "    Compute the spherical harmonics.\n",
    "\n",
    "    Parameters:\n",
    "    L (int): The maximum degree of the harmonics.\n",
    "    THETA (torch.Tensor): The theta angles.\n",
    "    PHI (torch.Tensor): The phi angles.\n",
    "    device (torch.device): The device to use for computations (default is CUDA if available).\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tensors containing the spherical harmonics for each degree l.\n",
    "    \"\"\"\n",
    "    P = associated_legendre_polynomials(L, torch.cos(PHI))\n",
    "    M2 =  [torch.zeros_like(THETA) for _ in range(2*(L-1)+1)]\n",
    "    output =  [[torch.zeros_like(THETA, device = device) for _ in range(2*l+1)] for l in range(L)]\n",
    "    \n",
    "    # Compute cosine and sine components for each m\n",
    "    for m in range(L):\n",
    "        if m > 0:\n",
    "            M2[L-1+m] = torch.cos(m*THETA)\n",
    "            M2[L-1-m] = torch.sin(m*THETA)\n",
    "        else:\n",
    "            M2[L-1]  = torch.ones_like(THETA)\n",
    "    \n",
    "    # Compute the spherical harmonics for each l and m\n",
    "    for l in range(L):\n",
    "        for m in range(l+1):\n",
    "            if m > 0:\n",
    "                output[l][l+m] = np.sqrt(2)*P[(l+1)*l//2+m]*np.sqrt((2*l+1)/(4*np.pi))*M2[L-1+m]\n",
    "                output[l][l-m] = np.sqrt(2)*P[(l+1)*l//2+m]*np.sqrt((2*l+1)/(4*np.pi))*M2[L-1-m]\n",
    "            else:\n",
    "                output[l][l  ] = P[(l+1)*l//2]*np.sqrt((2*l+1)/(4*np.pi))*M2[L-1]\n",
    "    \n",
    "    return torch.concat([torch.stack(output_i, dim = 0).to(device) for output_i in output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement the tensor product. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_product(f_j, Y_r, cg, W, rbf, in_degree, r_degree, out_degree):\n",
    "    # Tensor product using Clebsch-Gordan coefficients\n",
    "    in_degree_to_order = torch.tensor([int(np.floor(np.sqrt(i + 1)))-1 for i in range((in_degree + 1) ** 2)], dtype=torch.long)\n",
    "    r_degree_to_order = torch.tensor([int(np.floor(np.sqrt(i + 1)))-1 for i in range((r_degree + 1) ** 2)], dtype=torch.long)\n",
    "    out_degree_to_order = torch.tensor([int(np.floor(np.sqrt(i + 1)))-1 for i in range((out_degree + 1) ** 2)], dtype=torch.long)\n",
    "    # print(W.shape, in_degree_to_order.shape, r_degree_to_order.shape, out_degree_to_order.shape)\n",
    "    W_spanned = ((W[in_degree_to_order])[:, r_degree_to_order])[:, :, out_degree_to_order]\n",
    "    # print(cg.shape,  in_degree, r_degree, out_degree)\n",
    "    # print( f_j.shape)\n",
    "    # print(Y_r.shape)\n",
    "    # print((cg[:(in_degree + 1) ** 2, :(r_degree + 1) ** 2, :(out_degree + 1) ** 2, ]).shape)\n",
    "    # print(W_spanned.shape)\n",
    "    # print(rbf.shape)\n",
    "    out = torch.einsum('exa, ye, xyz, xyzabr, er->ezb', f_j, Y_r, cg[:(in_degree + 1) ** 2, :(r_degree + 1) ** 2, :(out_degree + 1) ** 2, ], W_spanned, rbf)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a simple Spherical GNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus\n",
    "\n",
    "# Define the Spherical GNN Layer\n",
    "class SphericalGNNLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, num_rbf=16, in_degree=0, r_degree=2, out_degree=2):\n",
    "        super(SphericalGNNLayer, self).__init__(aggr='add')\n",
    "        self.num_rbf = num_rbf\n",
    "        self.in_degree = in_degree\n",
    "        self.r_degree = r_degree\n",
    "        self.out_degree = out_degree\n",
    "        self.rbf_centers = torch.linspace(0, 5, num_rbf)  # Radial basis function centers\n",
    "        self.rbf_gamma = torch.tensor(1.0)  # Gamma parameter for RBF\n",
    "\n",
    "        \n",
    "        self.W = nn.Parameter(torch.randn( self.in_degree+1, self.r_degree+1, self.out_degree+1, in_channels, out_channels, self.num_rbf))\n",
    "\n",
    "        # Load Clebsch-Gordan coefficients\n",
    "        self.cg = torch.load('CG_tensor_2.pt')\n",
    "\n",
    "    def forward(self, x, pos, edge_index):\n",
    "        # Compute pairwise distances\n",
    "        row, col = edge_index\n",
    "        diff = pos[row] - pos[col]\n",
    "        dist = diff.norm(dim=-1)\n",
    "\n",
    "        # Compute RBF and spherical harmonics\n",
    "        rbf = torch.exp(-self.rbf_gamma[None] * (dist[:, None] - self.rbf_centers[None]) ** 2)\n",
    "        sh = self.spherical_harmonics(diff)\n",
    "\n",
    "        # Perform message passing\n",
    "        out = self.propagate(edge_index, x=x, rbf=rbf, sh=sh)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, rbf, sh):\n",
    "        # Tensor product of input features with spherical \n",
    "        x_j  = torch.reshape(x_j, (x_j.shape[0], (self.in_degree+1)**2, -1))\n",
    "        tp = tensor_product(x_j, sh, self.cg, self.W, rbf, self.in_degree, self.r_degree, self.out_degree)\n",
    "        return tp.reshape(tp.shape[0], -1)\n",
    "\n",
    "    \n",
    "\n",
    "    def spherical_harmonics(self, vectors):\n",
    "        # Compute spherical harmonics of vectors\n",
    "        theta = torch.atan2(vectors[:, 1], vectors[:, 0])\n",
    "        phi = torch.acos(vectors[:, 2] / vectors.norm(dim=-1))\n",
    "        sh = spherical_harmonics(self.r_degree + 1, theta, phi)\n",
    "        return sh\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "node_features = torch.randn(4, 3)  # 4 nodes, 3 features per node\n",
    "node_coords = torch.randn(4, 3)  # 4 nodes, 3D coordinates\n",
    "edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 0]], dtype=torch.long)  # Edges in COO format\n",
    "\n",
    "model = SphericalGNNLayer(in_channels=3, out_channels=2)\n",
    "output = model(node_features, node_coords, edge_index)\n",
    "\n",
    "print(\"Output Node Features:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of the Key Components\n",
    "\n",
    "1. **Radial Basis Functions (RBF):** A set of functions applied to the distances between nodes. The output is transformed via a linear layer and activation function to capture the radial dependencies.\n",
    "\n",
    "2. **Spherical Harmonics (SH):** Computed from the angular parts of vectors between nodes. SH helps encode the angular information of atomic positions.\n",
    "\n",
    "3. **Tensor Product:** Combines the input features with the spherical harmonics using Clebsch-Gordan coefficients to produce higher-degree features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Training a GNN on the QM9 Dataset using Custom Layers\n",
    "\n",
    "In this final exercise, you will train a GNN on the `QM9` dataset using one of the custom layers you have implemented: `InvariantMPNN`, `CartesianGNNLayer`, or `SphericalGNNLayer`.\n",
    "\n",
    "### Step 1: Load the QM9 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Load the QM9 dataset\n",
    "dataset = QM9(root='data/QM9')\n",
    "\n",
    "\n",
    "\n",
    "# choose the target\n",
    "\n",
    "\n",
    "'''\n",
    "+--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | Target | Property                         | Description                                                                       | Unit                                        |\n",
    "    +========+==================================+===================================================================================+=============================================+\n",
    "    | 0      | :math:`\\mu`                      | Dipole moment                                                                     | :math:`\\textrm{D}`                          |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 1      | :math:`\\alpha`                   | Isotropic polarizability                                                          | :math:`{a_0}^3`                             |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 2      | :math:`\\epsilon_{\\textrm{HOMO}}` | Highest occupied molecular orbital energy                                         | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 3      | :math:`\\epsilon_{\\textrm{LUMO}}` | Lowest unoccupied molecular orbital energy                                        | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 4      | :math:`\\Delta \\epsilon`          | Gap between :math:`\\epsilon_{\\textrm{HOMO}}` and :math:`\\epsilon_{\\textrm{LUMO}}` | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 5      | :math:`\\langle R^2 \\rangle`      | Electronic spatial extent                                                         | :math:`{a_0}^2`                             |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 6      | :math:`\\textrm{ZPVE}`            | Zero point vibrational energy                                                     | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 7      | :math:`U_0`                      | Internal energy at 0K                                                             | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 8      | :math:`U`                        | Internal energy at 298.15K                                                        | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 9      | :math:`H`                        | Enthalpy at 298.15K                                                               | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 10     | :math:`G`                        | Free energy at 298.15K                                                            | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 11     | :math:`c_{\\textrm{v}}`           | Heat capavity at 298.15K                                                          | :math:`\\frac{\\textrm{cal}}{\\textrm{mol K}}` |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 12     | :math:`U_0^{\\textrm{ATOM}}`      | Atomization energy at 0K                                                          | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 13     | :math:`U^{\\textrm{ATOM}}`        | Atomization energy at 298.15K                                                     | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 14     | :math:`H^{\\textrm{ATOM}}`        | Atomization enthalpy at 298.15K                                                   | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 15     | :math:`G^{\\textrm{ATOM}}`        | Atomization free energy at 298.15K                                                | :math:`\\textrm{eV}`                         |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 16     | :math:`A`                        | Rotational constant                                                               | :math:`\\textrm{GHz}`                        |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 17     | :math:`B`                        | Rotational constant                                                               | :math:`\\textrm{GHz}`                        |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "    | 18     | :math:`C`                        | Rotational constant                                                               | :math:`\\textrm{GHz}`                        |\n",
    "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
    "\n",
    "    \n",
    "'''\n",
    "\n",
    "target = 0\n",
    "\n",
    "\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "mean, std = mean[:, target].item(), std[:, target].item()\n",
    "\n",
    "\n",
    "# Splitting dataset...\n",
    "train_dataset = dataset[:110000]\n",
    "val_dataset = dataset[110000:120000]\n",
    "test_dataset = dataset[120000:]\n",
    "\n",
    "\n",
    "# DataLoader settings...\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Choose and Define the Model\n",
    "Select one of the custom layers (`InvariantMPNN`, `CartesianGNNLayer`, or `SphericalGNNLayer`) and define the model. Hereâ€™s an example using the `InvariantMPNN` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "class CustomGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, layer_type='invariant'):\n",
    "        super(CustomGNN, self).__init__()\n",
    "        if layer_type == 'invariant':\n",
    "            self.conv1 = InvariantMPNN(in_channels, hidden_channels)\n",
    "        elif layer_type == 'cartesian':\n",
    "            self.conv1 = CartesianGNNLayer(in_channels, hidden_channels)\n",
    "        elif layer_type == 'spherical':\n",
    "            self.conv1 = SphericalGNNLayer(in_channels, hidden_channels)\n",
    "        \n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, pos, edge_index, batch):\n",
    "        # Message Passing Layer\n",
    "        x = self.conv1(x, pos, edge_index)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # Global Pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = torch.relu(self.lin1(x))\n",
    "        return self.lin2(x)\n",
    "\n",
    "# Initialize the model\n",
    "model = CustomGNN(in_channels=11, hidden_channels=64, out_channels=1, layer_type='invariant')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.pos, data.edge_index, data.batch)\n",
    "        loss = F.mse_loss(out, data.y[:, target])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "    for data in loader:\n",
    "        data = data.to('cuda')\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.pos, data.edge_index, data.batch)\n",
    "            error += (out - data.y[:, target]).abs().sum().item()\n",
    "    return error / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "target = 0  # Select the property index to predict\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    test_error = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test MAE: {test_error:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
